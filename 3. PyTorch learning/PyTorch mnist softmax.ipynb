{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST Model on cpu\n",
      "============================================\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48ce12bc9bf4899b8855bc226c359c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c25c54f3cce44a98898eee9aed223bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd09b95f23742a7b39d1d7fef6a3afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3c1a412b2b492cb1d8d50877cada11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "\n",
      "\n",
      "\n",
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.284767\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.290339\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.299389\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.301178\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.300729\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.295107\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.304346\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.309787\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.304739\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.302683\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.292600\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.302290\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.301459\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.296963\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.294118\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.297726\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.302332\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.291765\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.289864\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.300089\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.288254\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.291067\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.299501\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.293577\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.288600\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.296628\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.300456\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.287930\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.285805\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.285049\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.284530\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.288219\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.287699\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.287593\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.305665\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.292854\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.280149\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.286869\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.293795\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.271844\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.277399\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.284592\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.281653\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.289586\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.278047\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.269919\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.275902\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.280986\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.254235\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.271136\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.257243\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.270433\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.263352\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.266436\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.262564\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.264900\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.248358\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.243604\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.231381\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.241924\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.228924\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.236286\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.241119\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.227403\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.230493\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.220190\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.217396\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.193732\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.177868\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.200883\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.157078\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.189224\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.166023\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.147465\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.135163\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.086170\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.060153\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.046407\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.022394\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 1.966977\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 1.958621\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 1.889632\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 1.851410\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 1.832510\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 1.877923\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 1.745346\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 1.752162\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 1.700263\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 1.657660\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 1.477575\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 1.474344\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.385097\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.379112\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.209493\n",
      "Training time: 0m 16s\n",
      "===========================\n",
      "Test set: Average loss: 0.0195, Accuracy: 6084/10000 (61%)\n",
      "Testing time: 0m 18s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.269857\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.167726\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.014772\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.127230\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.084342\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.068644\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 0.946556\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.030421\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.003878\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.964209\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.929858\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.953002\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.807699\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.761447\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.054711\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.880741\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.844121\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.843809\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.754144\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.603661\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.778751\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.604176\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.984266\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.671253\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.691823\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.560618\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.809402\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.533550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.650086\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.954104\n",
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.691263\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 1.011758\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.785463\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.696473\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.863253\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.849871\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.562136\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.625593\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.688746\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.619003\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.693617\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.501971\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.542925\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.450577\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.648209\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.615679\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.446968\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.452839\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.438573\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.514990\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.707932\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.472237\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.616964\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.291620\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.427875\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.571401\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.632034\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.559012\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.633668\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.621085\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.410695\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.594203\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.579312\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.391111\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.457479\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.548259\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.428497\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.572016\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.394552\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.591398\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.654051\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.398069\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.674602\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.621871\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.460911\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.422078\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.420171\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.324596\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.546634\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.566668\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.464038\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.660132\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.315914\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.443806\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.421667\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.540708\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.487373\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.477011\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.402571\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.333536\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.374112\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.508637\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.472357\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.302926\n",
      "Training time: 0m 20s\n",
      "===========================\n",
      "Test set: Average loss: 0.0066, Accuracy: 8776/10000 (88%)\n",
      "Testing time: 0m 22s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.486748\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.394156\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.293923\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.254486\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.504955\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.364146\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.346992\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.515558\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.519152\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.258504\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.534673\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.309948\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.344725\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.604418\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.497187\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.238336\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.288506\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.376404\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.445435\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.604500\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.551675\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.457407\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.212940\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.295724\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.311012\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.322912\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.240874\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.308481\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.279063\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.400672\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.395435\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.487268\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.375159\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.276161\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.160241\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.730220\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.396681\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.342186\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.260131\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.387722\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.377443\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.357030\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.371447\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.306796\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.514859\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.417872\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.494890\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.369696\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.447255\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.632178\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.578902\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.387261\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.258628\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.208007\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.145450\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.384712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.355675\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.177779\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.368799\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.377708\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.551928\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.485407\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.356483\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.396485\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.519561\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.221821\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.678321\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.148435\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.454391\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.243939\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.394431\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.421929\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.434377\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.443615\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.311497\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.293646\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.353640\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.273770\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.404967\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.413100\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.468296\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.404213\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.217110\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.432108\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.182007\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.329681\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.651369\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.250785\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.317276\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.311004\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.362641\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.505687\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.176080\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.288115\n",
      "Training time: 0m 19s\n",
      "===========================\n",
      "Test set: Average loss: 0.0045, Accuracy: 9130/10000 (91%)\n",
      "Testing time: 0m 22s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.541862\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.323495\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.492870\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.422710\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.215135\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.432623\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.129392\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.371264\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.298540\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.212108\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.168339\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.296515\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.312671\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.244344\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.272067\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.177378\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.406044\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.170845\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.492322\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.305296\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.545121\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.144098\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.355681\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.301693\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.277987\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.126263\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.186200\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.409592\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.316810\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.216228\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.342106\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.097936\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.117175\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.267950\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.297617\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.211559\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.498852\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.236131\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.308793\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.283449\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.131161\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.397915\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.152220\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.215924\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.136890\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.316182\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.307886\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.302557\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.297273\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.180054\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.171370\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.159638\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.178709\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.268515\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.275625\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.213213\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.225762\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.296396\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.399184\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.437840\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.359827\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.103543\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.143502\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.120061\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.193504\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.183924\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.266761\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.328713\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.166132\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.231925\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.214257\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.194867\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.251263\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.321393\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.283088\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.372722\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.284146\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.361750\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.178545\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.111632\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.109866\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.206119\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.339215\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.163256\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.243583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.228761\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.156809\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.117499\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.414072\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.349624\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.147947\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.180050\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.212153\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.159608\n",
      "Training time: 0m 19s\n",
      "===========================\n",
      "Test set: Average loss: 0.0034, Accuracy: 9374/10000 (94%)\n",
      "Testing time: 0m 21s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.210800\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.181022\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.171582\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.286298\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.245127\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.097475\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.242960\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.157810\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.263610\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.132124\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.176510\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.240366\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.442042\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.185020\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.102702\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.258739\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.297750\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.146524\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.255169\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.351910\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.190879\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.278827\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.384836\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.116040\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.082542\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.150577\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.132800\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.247471\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.151580\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.303159\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.174888\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.160744\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.262705\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.269763\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.112444\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.150616\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.342179\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.212852\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.099740\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.116842\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.292358\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.347605\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.064549\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.198980\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.196344\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.050377\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.173823\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.135870\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.212836\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.145750\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.185847\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.061527\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.216438\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.093809\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.235734\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.221087\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.227590\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.218761\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.201789\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.098899\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.141932\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.101612\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.071287\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.071410\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.072958\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.187553\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.174841\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.137494\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.242537\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.389801\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.231901\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.139132\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.118431\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.242292\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.149025\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.061486\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.059908\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.097149\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.125310\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.120808\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.209207\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.094321\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.217201\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.184644\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.261987\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.175195\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.094658\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.126866\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.157096\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.090249\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.188580\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.124430\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.103957\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.112606\n",
      "Training time: 0m 19s\n",
      "===========================\n",
      "Test set: Average loss: 0.0026, Accuracy: 9515/10000 (95%)\n",
      "Testing time: 0m 21s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.127939\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.072145\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.143835\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.125208\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.122498\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.162173\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.200544\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.134800\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.074215\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.162341\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.236578\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.136123\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.115810\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.304145\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.162250\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.081657\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.073388\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.150141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.164594\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.175116\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.087664\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.240210\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.125918\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.100785\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.353531\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.106932\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.142130\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.147663\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.175864\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.184268\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.130331\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.234851\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.076613\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.358474\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.132508\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.258899\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.136236\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.109357\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.135142\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.183779\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.299701\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.259881\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.100224\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.099576\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.109627\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.324296\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.101500\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.070151\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.113933\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.134364\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.103509\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.150438\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.141513\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.129768\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.141974\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.117489\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.046823\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.075410\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.117366\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.273630\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.166552\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.196943\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.262573\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.183456\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.165621\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.037747\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.196178\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.052497\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.175869\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.207616\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.066142\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.125542\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.117634\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.170805\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.152049\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.128086\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.072843\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.089449\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.134932\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.240177\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.238511\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.062912\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.045742\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.133415\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.046366\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.190239\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.037262\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.127527\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.204048\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.059731\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.171843\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.049951\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.232349\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.129303\n",
      "Training time: 0m 20s\n",
      "===========================\n",
      "Test set: Average loss: 0.0024, Accuracy: 9559/10000 (96%)\n",
      "Testing time: 0m 22s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.076312\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.078468\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.079525\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.190637\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.061201\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.142342\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.038245\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.121002\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.193685\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.048649\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.174155\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.041379\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.053967\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.228543\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.087229\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.025170\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.071424\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.199462\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.117586\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.198622\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.259209\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.031251\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.049748\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.124847\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.124342\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.258013\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.097604\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.101498\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.047745\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.105378\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.093013\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.079506\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.058040\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.090056\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.199319\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.118087\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.117070\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.350456\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.049200\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.067081\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.185722\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.043530\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.166367\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.172545\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.144293\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.124525\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.054157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.435424\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.079507\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.067063\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.121091\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.216721\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.218652\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.043810\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.089069\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.243132\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.442834\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.048064\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.108687\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.041692\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.031643\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.140933\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.152170\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.157059\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.067098\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.210425\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.069640\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.168020\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.037255\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.066054\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.344197\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.121647\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.028525\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.223893\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.066006\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.095293\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.183809\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.172592\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.051217\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.059627\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.067421\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.187753\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.141005\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.087019\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.112828\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.192892\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.077423\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.148804\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.099669\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.086968\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.077436\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.206439\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.201632\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.101458\n",
      "Training time: 0m 20s\n",
      "===========================\n",
      "Test set: Average loss: 0.0020, Accuracy: 9640/10000 (96%)\n",
      "Testing time: 0m 22s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.042282\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.024882\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.070227\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.120054\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.147665\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.143847\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.141363\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.119743\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.096746\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.149976\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.097276\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.044095\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.038905\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.097506\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.147757\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.094383\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.226099\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.063181\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.112580\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.068106\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.040282\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.301164\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.163122\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.156210\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.260714\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.060945\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.230725\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.061917\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.063055\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.078600\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.078416\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.264783\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.081089\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.073692\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.071746\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.148709\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.025329\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.129042\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.088803\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.058359\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.194748\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.102811\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.051206\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.023799\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.086222\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.167169\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.065984\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.067738\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.136021\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.040562\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.061132\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.080819\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.010028\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.057631\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.115852\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.042248\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.157462\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.095274\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.020559\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.148954\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.155169\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.058718\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.052768\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.201405\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.105855\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.024413\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.200675\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.130500\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.033934\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.058832\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.051268\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.086994\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.215029\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.160541\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.058642\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.090585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.066341\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.201887\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.063633\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.078187\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.108548\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.025139\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.067515\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.084810\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.040080\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.084198\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.026135\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.042256\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.108527\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.089566\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.027502\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.072324\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.029391\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.141770\n",
      "Training time: 0m 20s\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9678/10000 (97%)\n",
      "Testing time: 0m 22s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.082887\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.051467\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.087468\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.149931\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.214424\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.075341\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.114132\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.084891\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.110223\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.052667\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.047504\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.042042\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.078709\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.159476\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.087169\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.079396\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.035152\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.077486\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.077159\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.162778\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.031888\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.024405\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.117630\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.177461\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.146982\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.098942\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.105338\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.025397\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.121923\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.086192\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.058193\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.048366\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.016995\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.154832\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.128201\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.105845\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.026945\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.073562\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.174228\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.117018\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.087297\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.210269\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.079670\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.103184\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.083420\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.050063\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.205336\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.043513\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.139529\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.092717\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.184694\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.173198\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.046940\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.323102\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.032075\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.006888\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.078359\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.027673\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.093159\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.026778\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.051998\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.286213\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.050449\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.275421\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.053479\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.072043\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.143533\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.116157\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.088209\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.040072\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.047097\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.120001\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.089752\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.076971\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.132795\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.029635\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.021143\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.118814\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.073164\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.071267\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.064443\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.086145\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.031990\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.039792\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.084608\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.075358\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.102450\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.030692\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.031999\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.046326\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.045676\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.082298\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.062375\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.134272\n",
      "Training time: 0m 20s\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9686/10000 (97%)\n",
      "Testing time: 0m 22s\n",
      "Total Time: 3m 11s\n",
      "Model was trained on cpu!\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1, 10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "        test()\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "    m, s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch===1.4.0 in c:\\users\\vikaa\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Collecting torchvision===0.5.0\n",
      "  Downloading torchvision-0.5.0-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\vikaa\\appdata\\roaming\\python\\python37\\site-packages (from torchvision===0.5.0) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\vikaa\\anaconda3\\lib\\site-packages (from torchvision===0.5.0) (7.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vikaa\\anaconda3\\lib\\site-packages (from torchvision===0.5.0) (1.18.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
