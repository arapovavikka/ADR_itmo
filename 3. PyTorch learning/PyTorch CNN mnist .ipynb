{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST Model on cpu\n",
      "============================================\n",
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.285903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikaa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.294761\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.279080\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.260328\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.198345\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.191966\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.143641\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.114134\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 1.977794\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 1.870374\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 1.718560\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 1.452855\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 1.368115\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 0.969630\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 0.855964\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 0.848161\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 0.644653\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 0.609679\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 0.593687\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 0.463206\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 0.599134\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 0.602500\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 0.450916\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 0.555340\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 0.486002\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 0.438832\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 0.555505\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 0.316644\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 0.311839\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 0.289310\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 0.426550\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 0.453534\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 0.399597\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 0.190187\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 0.718876\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 0.307496\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 0.436069\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 0.255960\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 0.307053\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 0.244828\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 0.262262\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 0.569829\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 0.333411\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 0.465335\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 0.326313\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 0.288384\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 0.382696\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 0.281387\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 0.307593\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 0.179857\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 0.361844\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 0.340086\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 0.164157\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 0.292674\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 0.324854\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 0.443287\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 0.261593\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 0.323637\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 0.366687\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 0.285893\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 0.357473\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 0.141329\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 0.230696\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 0.222080\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 0.299932\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 0.236997\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 0.215360\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 0.334176\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 0.137119\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 0.168460\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 0.385318\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 0.202185\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 0.239230\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 0.233857\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 0.133577\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 0.151761\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 0.152025\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 0.076150\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 0.198681\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 0.177431\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 0.147356\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 0.138473\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 0.222081\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 0.231727\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 0.195981\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 0.210724\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 0.150014\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 0.228340\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 0.101484\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 0.235459\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 0.132177\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 0.145553\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 0.220075\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 0.194816\n",
      "Training time: 0m 43s\n",
      "===========================\n",
      "Test set: Average loss: 0.0027, Accuracy: 9468/10000 (95%)\n",
      "Testing time: 0m 46s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 0.152354\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 0.101735\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 0.236359\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 0.257921\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 0.124494\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 0.241902\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 0.434930\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 0.062987\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 0.102647\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.075333\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.197052\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.166806\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.087128\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.131445\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.138758\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.078886\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.124472\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.207862\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.176967\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.119407\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.080517\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.138637\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.228560\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.147373\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.163566\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.206263\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.207010\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.126595\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.067765\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.127670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.132229\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.129779\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.358753\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.101877\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.187456\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.122306\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.216243\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.268105\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.124060\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.055892\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.130189\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.171030\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.035406\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.087774\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.054812\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.067337\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.159625\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.059399\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.112278\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.048683\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.045384\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.219566\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.110068\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.118826\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.077814\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.285052\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.040177\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.146751\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.197601\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.219521\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.091465\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.024198\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.160206\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.123879\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.237446\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.100709\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.148672\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.194482\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.101853\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.361311\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.096866\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.118285\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.087489\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.151802\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.164910\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.081748\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.051025\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.311398\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.068585\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.047575\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.072823\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.040494\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.176037\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.181952\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.110992\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.175482\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.212563\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.197504\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.103033\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.087732\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.073735\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.240244\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.101563\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.101991\n",
      "Training time: 0m 45s\n",
      "===========================\n",
      "Test set: Average loss: 0.0019, Accuracy: 9647/10000 (96%)\n",
      "Testing time: 0m 48s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.219648\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.106726\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.095661\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.206576\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.169614\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.181647\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.334610\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.085574\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.148883\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.082564\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.033584\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.106660\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.079407\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.163811\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.084864\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.103913\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.237691\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.134413\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.144960\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.089482\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.072457\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.079234\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.019108\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.132491\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.052505\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.161040\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.107476\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.107957\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.202407\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.061348\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.081646\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.124094\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.109155\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.166711\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.246469\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.036486\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.074052\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.071665\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.043840\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.230405\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.079470\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.141454\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.192308\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.022064\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.048620\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.214427\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.107678\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.157642\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.175003\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.127956\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.337545\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.206815\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.041332\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.049826\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.107601\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.115596\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.171447\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.102202\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.116271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.095979\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.186367\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.114020\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.061816\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.047192\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.031762\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.169324\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.052772\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.125267\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.293435\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.039933\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.096159\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.107801\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.137704\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.113139\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.080431\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.134114\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.124517\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.106848\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.126220\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.245869\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.048771\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.090335\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.092715\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.103835\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.239114\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.083682\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.068918\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.078619\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.117143\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.051862\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.028836\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.124986\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.105997\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.086560\n",
      "Training time: 0m 44s\n",
      "===========================\n",
      "Test set: Average loss: 0.0013, Accuracy: 9752/10000 (98%)\n",
      "Testing time: 0m 47s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.121491\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.138280\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.158529\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.058116\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.033288\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.175606\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.078028\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.127516\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.121050\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.150491\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.082781\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.067708\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.106671\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.103211\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.159587\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.049527\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.027102\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.049462\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.071872\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.055477\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.099532\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.085895\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.115232\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.049202\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.108211\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.075305\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.052240\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.055404\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.029374\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.042654\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.090495\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.076104\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.068273\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.220279\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.085534\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.099762\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.093851\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.160422\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.047396\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.077933\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.039396\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.104840\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.083183\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.059903\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.201923\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.016152\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.039991\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.049076\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.061502\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.085222\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.077641\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.051274\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.033474\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.086085\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.022714\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.156748\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.086058\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.031687\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.030393\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.107004\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.091433\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.046890\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.175799\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.071195\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.053484\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.019721\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.047859\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.015052\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.113892\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.055749\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.047037\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.037888\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.055257\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.183573\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.060944\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.082163\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.094582\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.216578\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.231234\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.048266\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.044917\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.053751\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.162486\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.028119\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.028619\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.050369\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.027995\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.055750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.068586\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.077465\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.157332\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.076484\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.021583\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.048057\n",
      "Training time: 0m 44s\n",
      "===========================\n",
      "Test set: Average loss: 0.0012, Accuracy: 9762/10000 (98%)\n",
      "Testing time: 0m 46s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.028582\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.051377\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.033130\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.052141\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.031086\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.162800\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.042156\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.094236\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.048394\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.132910\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.020812\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.015056\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.046271\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.023748\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.066688\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.113923\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.102719\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.055023\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.034789\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.105640\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.048007\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.145719\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.054491\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.014665\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.124251\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.098376\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.015817\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.080049\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.034373\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.077262\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.154677\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.147367\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.058947\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.024900\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.037567\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.082305\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.131514\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.130612\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.049045\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.073165\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.027842\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.138222\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.148321\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.098658\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.045341\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.058422\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.048088\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.080974\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.052629\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.069203\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.080034\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.013182\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.041774\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.070082\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.126170\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.120094\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.015707\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.054764\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.052077\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.052307\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.055958\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.065440\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.028702\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.008827\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.056339\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.079560\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.062909\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.135716\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.135095\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.164045\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.055087\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.055011\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.058482\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.130595\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.027370\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.018287\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.138547\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.011003\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.046587\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.084205\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.142083\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.090407\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.034790\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.081897\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.084037\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.025138\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.107645\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.094372\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.084405\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.106576\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.054922\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.075899\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.101587\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.186084\n",
      "Training time: 0m 44s\n",
      "===========================\n",
      "Test set: Average loss: 0.0011, Accuracy: 9781/10000 (98%)\n",
      "Testing time: 0m 47s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.060801\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.057913\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.046471\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.053572\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.066070\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.107464\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.081337\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.058294\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.028401\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.089077\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.120975\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.071096\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.196858\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.012896\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.097696\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.048566\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.022121\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.117535\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.119157\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.461549\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.050097\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.034432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.028818\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.169579\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.253935\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.025224\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.028992\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.194134\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.033319\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.141061\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.054190\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.092844\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.078808\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.028926\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.029523\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.105438\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.098065\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.122140\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.062942\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.070855\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.092772\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.059728\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.061930\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.080054\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.082611\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.013958\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.075637\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.111676\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.043541\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.101909\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.072592\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.079248\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.029651\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.057081\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.107289\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.074238\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.122951\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.030753\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.106198\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.077273\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.053830\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.043723\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.018313\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.019540\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.067024\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.051658\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.094530\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.035555\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.083850\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.052650\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.011491\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.047182\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.011572\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.011697\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.138757\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.078942\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.023356\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.013425\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.038075\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.040593\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.055060\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.034558\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.026439\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.020389\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.041079\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.072324\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.034555\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.030627\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.038975\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.019618\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.023752\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.047471\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.048658\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.038487\n",
      "Training time: 0m 44s\n",
      "===========================\n",
      "Test set: Average loss: 0.0010, Accuracy: 9800/10000 (98%)\n",
      "Testing time: 0m 47s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.025902\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.016896\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.020608\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.072291\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.076375\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.082272\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.021336\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.092538\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.031197\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.049220\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.056410\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.056102\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.019646\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.116595\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.009662\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.050315\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.105162\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.032492\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.031476\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.150357\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.023419\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.017614\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.062238\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.084137\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.028928\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.041471\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.030114\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.080119\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.055425\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.097662\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.029828\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.054437\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.043140\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.095881\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.052505\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.131361\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.011821\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.023234\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.073700\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.075532\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.156132\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.085517\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.079224\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.049980\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.057461\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.032710\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.122900\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.043768\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.137913\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.053378\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.031131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.044025\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.029730\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.083707\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.215019\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.017133\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.106891\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.029105\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.040900\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.047296\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.013363\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.219438\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.018429\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.112124\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.078361\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.083343\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.044200\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.072750\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.033580\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.055586\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.060120\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.151662\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.033979\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.015819\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.018321\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.025458\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.054426\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.046546\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.070169\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.021536\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.055649\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.095538\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.020575\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.033687\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.019355\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.025234\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.165192\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.088109\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.032461\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.089840\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.208885\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.030607\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.045771\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.059677\n",
      "Training time: 0m 44s\n",
      "===========================\n",
      "Test set: Average loss: 0.0009, Accuracy: 9825/10000 (98%)\n",
      "Testing time: 0m 47s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.052724\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.034907\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.108402\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.011421\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.036880\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.071274\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.096691\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.034314\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.049660\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.034695\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.008424\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.027074\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.035873\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.050179\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.049995\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.050820\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.042373\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.022695\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.098222\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.030877\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.025838\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.131692\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.083726\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.070161\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.024743\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.007889\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.091840\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.006650\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.029085\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.029143\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.116404\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.094830\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.047587\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.042462\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.030531\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.031532\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.035195\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.155357\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.070748\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.008806\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.032978\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.141323\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.044040\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.049970\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.064900\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.038046\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.054167\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.031739\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.075841\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.038286\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.089524\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.030129\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.099633\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.114568\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.011491\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.099274\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.089867\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.073592\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.054863\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.056271\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.087172\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.138465\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.046733\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.029578\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.008717\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.032159\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.108911\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.031427\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.028887\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.033600\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.011309\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.032077\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.013290\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.015713\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.027076\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.036869\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.355676\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.086782\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.012096\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.045353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.183169\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.016297\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.015662\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.040592\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.004024\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.056253\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.006192\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.160925\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.075980\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.115540\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.038952\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.053119\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.012888\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.053529\n",
      "Training time: 0m 45s\n",
      "===========================\n",
      "Test set: Average loss: 0.0009, Accuracy: 9829/10000 (98%)\n",
      "Testing time: 0m 48s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.043762\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.075429\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.014973\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.013812\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.051280\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.016728\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.080301\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.029533\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.004081\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.080551\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.014037\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.073260\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.114283\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.022469\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.062968\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.097651\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.040415\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.092676\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.015604\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.099128\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.066787\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.054495\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.022287\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.085813\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.111815\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.055782\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.038127\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.077460\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.016696\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.016897\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.054075\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.020742\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.095157\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.011858\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.055981\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.111322\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.115095\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.028406\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.107619\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.041441\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.011517\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.051114\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.066698\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.067794\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.123630\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.069902\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.033766\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.135985\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.048619\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.020794\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.058015\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.027999\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.035784\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.017980\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.035601\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.017590\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.102654\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.061766\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.076856\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.241886\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.017416\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.084857\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.027776\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.013233\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.031599\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.020142\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.035161\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.016688\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.069452\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.217597\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.081230\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.044886\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.109399\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.027216\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.068496\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.016075\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.139096\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.017930\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.030565\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.029805\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.125211\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.071481\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.037331\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.022638\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.010432\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.015069\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.119266\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.088023\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.021751\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.063561\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.097293\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.042066\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.023281\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.036977\n",
      "Training time: 0m 46s\n",
      "===========================\n",
      "Test set: Average loss: 0.0008, Accuracy: 9837/10000 (98%)\n",
      "Testing time: 0m 49s\n",
      "Total Time: 7m 5s\n",
      "Model was trained on cpu!\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    since = time.time()\n",
    "    for epoch in range(1, 10):\n",
    "        epoch_start = time.time()\n",
    "        train(epoch)\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "        test()\n",
    "        m, s = divmod(time.time() - epoch_start, 60)\n",
    "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "    m, s = divmod(time.time() - since, 60)\n",
    "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
